{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Welcome to the ACCESS-OM3 wiki!</p> <p>See the links on the right, particularly the quick start.</p> <p>This wiki is a work in progress - feel free to contribute!</p>"},{"location":"Architecture/","title":"ACCESS-OM3 architecture","text":"<p>The schematic below illustrates the structure of the MOM6-CICE6-WW3 ACCESS-OM3 executable. ACCESS-OM3 is a single executable, consisting of the NUOPC driver (the main program) and several model components, each wrapped in a NUOPC cap; the caps are coupled through the CMEPS mediator via NUOPC connectors (see the coupling page for more information).</p> <p></p>"},{"location":"Architecture/#overview-of-codebase","title":"Overview of codebase","text":"<p>The ACCESS-OM3 code repository consists mostly of submodules containing the code for each model component.</p> <p>The top level code (main program) for an ACCESS-OM3 executable is the CMEPS NUOPC driver <code>CMEPS/CMEPS/cesm/driver/esmApp.F90</code>.</p> <p>The build system compiles a set of executables containing the driver, CMEPS NUOPC mediator and different selections of these model components: - ocean: MOM6 active model or DOCN prescribed data model from CDEPS or nothing (stub) - sea ice: CICE6 active model or DICE prescribed data model from CDEPS or nothing (stub) - waves: WW3 active model or nothing (stub) - atmosphere: DATM prescribed data model from CDEPS - runoff: DROF prescribed data model from CDEPS</p> <p>The model components are coupled exclusively through the mediator via their NUOPC caps: MOM6, CICE6, WW3, DOCN, DICE, DATM and DROF.</p> <p>NUOPC is provided via the ESMF library in <code>/g/data/ik11/spack/</code> and was built by https://github.com/COSIMA/spack-config</p>"},{"location":"Building/","title":"Building","text":"<p>If you don't want to use a precompiled executable from an ACCESS-OM3 release, you can build it yourself.</p> <p>Building access-om3 requires membership of the <code>ik11</code> project - apply at https://my.nci.org.au/mancini/project/ik11 if needed.</p> <p>First clone access-om3 following the steps in the README. Then do</p> <pre><code>cd access-om3\n./build.sh\n</code></pre> <p>After a little while you'll get shiny new executables:</p> <pre><code>Release/bin/access-om3-CICE6-WW3\nRelease/bin/access-om3-MOM6-CICE6\nRelease/bin/access-om3-MOM6-CICE6-WW3\nDebug/bin/access-om3-CICE6-WW3\nDebug/bin/access-om3-MOM6-CICE6\nDebug/bin/access-om3-MOM6-CICE6-WW3\n</code></pre> <p>The executables in <code>Releases</code> are optimised for production use. The <code>Debug</code> versions may be useful for getting more information on model crashes, but should not be used for production runs as they are much slower.</p> <p>The executable names are labelled by the included model components. There are additional combinations of components which can be built by changing <code>OFF</code> to <code>ON</code> in this section of <code>CMakeLists.txt</code> and running <code>./build.sh</code> again.</p>"},{"location":"Building/#a-note-on-dependencies","title":"A note on dependencies","text":"<p>ACCESS-OM3 has several dependencies which are unavailable from NCI, so we supply them via Spack using https://github.com/COSIMA/spack-config which is installed in <code>/g/data/ik11/spack/</code>.</p>"},{"location":"Building/#todo","title":"TODO","text":"<ul> <li>comment here on whether the executables are suitable for all cpus (ie queues) on gadi</li> <li>We also want to coordinate with these plans https://github.com/ACCESS-NRI/model_builder</li> </ul>"},{"location":"Building/#for-developers","title":"For developers","text":"<p>Spack-based build instructions are here: https://github.com/ACCESS-NRI/ACCESS-OM2/blob/main/DEVELOPERS.md and the spack environment is at https://github.com/accESS-NRI/access-om3</p> <p>To produce release and release-prototypes, raise a PR with the changes on https://github.com/accESS-NRI/access-om3. This will deploy at github workflow to automatically build the requested model binary.</p>"},{"location":"Configurations/","title":"CMEPS-coupled configurations","text":"<p>ACCESS-OM3 configurations are provided via branches in these repositories. They all have prescribed data atmosphere and runoff. - <code>access-om3-wav-configs</code>: 3-way coupled MOM6-CICE6-WW3 ocean, sea ice and waves - <code>access-om3-configs</code>: 2-way coupled MOM6-CICE6 ocean and sea ice (no waves) - <code>CICE6-WW3</code>: 2-way coupled CICE6-WW3 sea ice and waves (prescribed data ocean), not currently working</p>"},{"location":"Configurations/#overview-of-the-cmeps-configurations","title":"Overview of the CMEPS configurations","text":"<p>The three CMEPS-coupled configurations have much in common. Here we provide a quick overview of the common features, using examples from the <code>1deg_jra55do_ryf</code> branch of <code>access-om3-configs</code> (i.e. MOM6-CICE6).</p>"},{"location":"Configurations/#what-the-configuration-files-are-for","title":"What the configuration files are for","text":"<ul> <li><code>config.yaml</code>: used by <code>payu</code> for model setup and run (YAML format)</li> <li><code>datm_in</code>: sets stream-independent data atmosphere parameters (in Fortran namelist format)</li> <li><code>datm.streams.xml</code>: sets input files and other stream-dependent input data for data atmosphere in this XML format</li> <li><code>diag_table</code>: MOM6 diagnostics in this format; may be generated from a <code>diag_table_source.yaml</code> YAML file by <code>make_diag_table.py</code></li> <li><code>drof_in</code>: sets stream-independent data runoff parameters (in Fortran namelist format)</li> <li><code>drof.streams.xml</code>: sets input files and other stream-dependent input data for data runoff in this XML format</li> <li><code>drv_in</code>: NUOPC parameters for the driver (in Fortran namelist format)</li> <li><code>fd.yaml</code>: NUOPC field dictionary (YAML format) read by the NUOPC driver; defines standard metadata for fields that may be available for import and/or export from model components; <code>standard_name</code>s are used for field pairing during initialisation</li> <li><code>ice_in</code>: CICE6 parameters (in Fortran namelist format)</li> <li><code>input.nml</code>: a few MOM6 parameters (in Fortran namelist format)</li> <li><code>MOM_input</code>: most of the MOM6 parameters, in this format</li> <li><code>MOM_override</code>: more MOM6 parameters in this format, overriding things in <code>MOM_input</code></li> <li><code>nuopc.runconfig</code>: read by NUOPC driver; supplies driver-related parameters for model components; parameters documented here; the file is a mix of Resource File and Fortran namelist formats</li> <li><code>nuopc.runseq</code>: read by NUOPC driver; defines model component run sequence using this syntax</li> </ul>"},{"location":"Configurations/#where-to-set-parameters","title":"Where to set parameters","text":""},{"location":"Configurations/#model-executable","title":"Model executable","text":"<ul> <li><code>exe</code> in <code>config.yaml</code>. Pre-built executables are available in <code>/g/data/ik11/inputs/access-om3/bin/</code> or you can build your own. Executable names indicate the available model components and the git hash of the source code used. Avoid using the <code>Debug</code> versions for production runs as they are much slower.</li> </ul>"},{"location":"Configurations/#coupling","title":"Coupling","text":"<ul> <li>active model components</li> <li><code>component_list</code> and entries in <code>ALLCOMP_attributes</code> section in <code>nuopc.runconfig</code>, e.g.</li> </ul> <pre><code>component_list: MED ATM ICE OCN ROF\nALLCOMP_attributes::\n     ATM_model = datm  # data atmosphere\n     GLC_model = sglc  # no glaciers/land ice (stub)\n     ICE_model = cice  # active sea ice (cice)\n     LND_model = slnd  # no land model (stub)\n     MED_model = cesm  # mediator\n     OCN_model = mom   # active ocean model (mom6)\n     ROF_model = drof  # data runoff\n     WAV_model = swav  # no wave model (stub)\n     ...\n</code></pre> <ul> <li>components and fields to couple</li> <li>See the coupling architecture here</li> <li>Coupling is negotiated between model components during initialization of a model run. See here: \"CMEPS advertises all possible fields that can be imported to and exported by the mediator for the target coupled system. Not all of these fields will be connected to the various components. The connections will be determined by what the components advertise in their respective advertise phase.\"</li> <li><code>fd.yaml</code>: NUOPC field dictionary defines standard metadata for fields that may be available for import and/or export from model components; standard_names are used for field pairing during initialisation</li> <li>the fields available to be imported/exported for coupling are determined by the NUOPC cap code for MOM6, CICE6, WW3, DATM and DROF and recorded in the mediator log output file: <code>grep Advert archive/output000/log/med.log</code></li> <li>whether those fields are actually coupled is determined by the CMEPS mediator at run time (see here).<ul> <li>the coupling between components is recorded in the mediator log output file: <code>grep -A 9 \"Active coupling flags\" archive/output000/log/med.log</code></li> <li>the mediator log output file also lists the individual fields that are coupled and where the coupled fluxes are calculated: <code>grep '^ mapping' archive/output000/log/med.log</code>; see here for how to decode this</li> </ul> </li> <li>also see <code>wav_coupling_to_cice</code> in <code>nuopc.runconfig</code></li> <li>remapping/redistribution method for coupled fields</li> <li>The remapping method used for each field is recorded in the mediator log output file: <code>grep '^ mapping' archive/output000/log/med.log</code>; see here for how to decode this</li> <li><code>datm.streams.xml</code> and <code>drof.streams.xml</code> specify <code>&lt;mapalgo&gt;bilinear&lt;/mapalgo&gt;</code> but there are better options - see here and here</li> <li><code>rof2ocn_ice_rmapname</code> and <code>rof2ocn_liq_rmapname</code> in <code>MED_attributes</code> in <code>nuopc.runconfig</code></li> <li><code>*map*</code> in <code>MED_attributes</code> in <code>nuopc.runconfig</code></li> <li><code>remapMethod</code> in <code>nuopc.runseq</code>; options are <code>redist</code>, <code>bilinear</code> (the default), <code>patch</code>, <code>nearest_stod</code>, <code>nearest_dtos</code>, <code>conserve</code>. For strict bit-for-bit reproducibility <code>srcTermProcessing=1</code> and <code>termOrder=srcseq</code> are also required. See details here and here and this detailed explanation.</li> <li>time interpolation of coupled fields</li> <li>specified via <code>tintalgo</code> in <code>datm.streams.xml</code> and <code>drof.streams.xml</code> - see here for options</li> </ul>"},{"location":"Configurations/#processor-layout-see-here","title":"Processor layout - see here","text":"<ul> <li>entries in <code>PELAYOUT_attributes</code> section in <code>nuopc.runconfig</code></li> <li>may need to adjust <code>max_blocks</code> in <code>ice_in</code></li> <li>may need a <code>mem: 192GB</code> entry in <code>config.yaml</code> if you are using less than a full node</li> </ul>"},{"location":"Configurations/#io-layout","title":"IO layout","text":"<ul> <li>entries in <code>*_modelio</code> sections in <code>nuopc.runconfig</code></li> <li>for <code>pio_typename</code>.<ul> <li>Use <code>netcdf4p</code> for parallel IO. Don't use <code>netcdf4c</code> (deprecated) or <code>pnetcdf</code> (not included in dependencies).</li> <li><code>netcdf</code> only uses one PE (<code>pio_root</code>) for IO</li> </ul> </li> <li>MOM6 uses FMS for IO and doesn't use the settings in the <code>OCN_modelio</code> section. Instead, IO settings can be configured in the <code>fms2_io_nml</code> namelist group in <code>input.nml</code></li> </ul>"},{"location":"Configurations/#case-name","title":"case name","text":"<ul> <li><code>case_name</code> in <code>ALLCOMP_attributes</code> in <code>nuopc.runconfig</code></li> </ul>"},{"location":"Configurations/#grids","title":"grids","text":"<ul> <li><code>mesh_atm</code>, <code>mesh_ice</code>, <code>mesh_ocn</code> in <code>ALLCOMP_attributes</code> in <code>nuopc.runconfig</code></li> <li><code>mesh_rof</code> in <code>ROF_attributes</code> in <code>nuopc.runconfig</code></li> <li>grid dimensions <code>*_nx</code>, <code>*_ny</code> in <code>MED_attributes</code> in <code>nuopc.runconfig</code></li> </ul>"},{"location":"Configurations/#coupling-diagnostics","title":"coupling diagnostics","text":"<ul> <li><code>*budget*</code> in <code>MED_attributes</code> in <code>nuopc.runconfig</code></li> <li><code>hist*</code> in <code>MED_attributes</code> in <code>nuopc.runconfig</code><ul> <li><code>histaux_*_flds</code> is either a colon-delimited list of fields to output, or <code>all</code> to output everything; see CMEPS field naming convention to decode these</li> <li><code>grep hist archive/output000/log/med.log</code> will show you when data was written</li> </ul> </li> </ul>"},{"location":"Configurations/#verbosity-in-nuopc-log-files-archiveoutputloglog","title":"verbosity in NUOPC log files (<code>archive/output*/log/*.log</code>)","text":"<ul> <li><code>Verbosity</code> in attributes for model components in <code>nuopc.runconfig</code>; can be <code>off</code>, <code>low</code>, <code>high</code>, <code>max</code> - see here - but doesn't seems to make any difference, perhaps due to this issue.</li> </ul>"},{"location":"Configurations/#calendar","title":"calendar","text":"<ul> <li><code>calendar</code> in <code>CLOCK_attributes</code> in <code>nuopc.runconfig</code>; can be either <code>NO_LEAP</code> or <code>GREGORIAN</code></li> <li>also set <code>use_leap_years = .true.</code> in <code>ice_in</code> for Gregorian calendar</li> </ul>"},{"location":"Configurations/#start-date","title":"start date","text":"<ul> <li><code>start_ymd</code> in <code>CLOCK_attributes</code> in <code>nuopc.runconfig</code></li> </ul>"},{"location":"Configurations/#run-length","title":"run length","text":"<ul> <li><code>stop_n</code> and <code>stop_option</code> in <code>CLOCK_attributes</code> in <code>nuopc.runconfig</code>; available units for <code>stop_option</code> are listed here</li> </ul>"},{"location":"Configurations/#run-sequence","title":"run sequence","text":"<ul> <li>The order which components are run is specified in <code>nuopc.runseq</code>. The order also impacts whether components run sequentially or in parallel. Normally we specify CICE and MOM to run in subsequent lines in <code>nuopc.runseq</code>, and as long as they are on different processors, they run in parallel as these steps do not depend on each other.</li> <li>To run MOM before CICE, specify all OCN related steps in the nuopc.runseq before all ICE related steps (see example here). This will be very slow and resource inefficient and is for testing / debugging only. It does reduce the coupling related lag in stress between the sea-ice and ocean (see Morrison 2024 slides</li> </ul>"},{"location":"Configurations/#restart-frequency","title":"restart frequency","text":"<ul> <li><code>restart_n</code> and <code>restart_option</code> in <code>CLOCK_attributes</code> in <code>nuopc.runconfig</code>; available units for <code>restart_option</code> are listed here</li> </ul>"},{"location":"Configurations/#timesteps","title":"timesteps","text":"<ul> <li>there is a complex set of interrelated timesteps - see here and here to understand how they interact</li> <li>coupling and driver timesteps - see here<ul> <li><code>*_cpl_dt</code> in <code>CLOCK_attributes</code> in <code>nuopc.runconfig</code></li> <li><code>nuopc.runseq</code></li> </ul> </li> <li>MOM6 timestepping - see here<ul> <li>There are 4 timesteps. From shortest to longest they are: barotropic, baroclinic (Lagrangian), tracer, vertical remapping - see here and here and here</li> </ul> </li> <li>CICE6 timestepping - see here<ul> <li>There are 3 timesteps. From shortest to longest they are elastic, dynamic and thermodynamic - see here</li> <li>The thermodynamic timestep is determined by the coupling (and driver) timestep (so <code>dt</code> should not be explicitly set in <code>ice_in</code> - see here)</li> <li><code>ndtd</code> in <code>ice_in</code> sets the number of dynamic timesteps in each thermodynamic timestep; increasing this can resolve \"bad departure points\" CFL errors</li> <li><code>ndte</code> in <code>ice_in</code> sets the number of elastic timesteps in each dynamic timestep if the classic EVP or EAP method is used (<code>kdyn</code> = 1 or 2, <code>revised_evp</code> = false)</li> </ul> </li> </ul>"},{"location":"Configurations/#walltime-limit","title":"walltime limit","text":"<ul> <li><code>walltime</code> in <code>config.yaml</code></li> </ul>"},{"location":"Configurations/#number-of-ensemble-members","title":"number of ensemble members","text":"<ul> <li><code>ninst</code> in <code>PELAYOUT_attributes</code> in <code>nuopc.runconfig</code></li> </ul>"},{"location":"Configurations/#forcing-data","title":"forcing data","text":"<ul> <li>see the Forcing page</li> <li>atmospheric forcing<ul> <li><code>datm.streams.xml</code> sets individual file paths relative to this entry in the <code>input</code> section of <code>config.yaml</code>; see DATM and streams docs</li> </ul> </li> <li>runoff<ul> <li><code>drof.streams.xml</code> sets individual file paths relative to this entry in the <code>input</code> section of <code>config.yaml</code>; see DROF and streams docs</li> </ul> </li> </ul>"},{"location":"Configurations/#see-also","title":"See also","text":"<ul> <li>ACCESS-NRI fork of CESM: https://github.com/ACCESS-NRI/CESM - see here</li> <li>MOM6 in CESM: https://github.com/ESCOMP/MOM_interface/wiki</li> <li>Shuo Li's WW3-MOM6-SIS2 FMS-coupled model configuration https://github.com/shuoli-code/MOM6_WW3_SIS2_coupled</li> </ul>"},{"location":"Coupling/","title":"Coupling","text":"<p>As shown on the model architecture page, we couple the model components using NUOPC with the CMEPS mediator. NUOPC is an interoperability layer for ESMF which standardises how model components interact. See discussions here and here for more information.</p>"},{"location":"Coupling/#coupler-docs","title":"Coupler docs","text":"<ul> <li>Overview of how NUOPC works</li> <li>CMEPS docs</li> <li>NUOPC and ESMF docs</li> <li>NUOPC how-to</li> <li>NUOPC reference</li> <li>ESMF superstructure</li> <li>ESMF glossary</li> <li>MOM6 NUOPC cap docs</li> </ul>"},{"location":"Coupling/#how-to-determine-which-fields-are-coupled","title":"How to determine which fields are coupled","text":"<p>The coupled fields and remapping methods used are recorded in the mediator log output file and can be found with <code>grep '^ mapping' archive/output000/log/med.log</code>; see here for how to decode this. See the Configurations page for details on how the coupling is determined.</p>"},{"location":"Forcing-data-models/","title":"Forcing","text":"<p>Forcing is provided via CDEPS data models documented here, in particular</p> <ul> <li>DATM for the atmosphere</li> <li>DROF for runoff</li> </ul>"},{"location":"Forcing-data-models/#coupling","title":"Coupling","text":"<ul> <li>DATM and DROF are coupled to the other components via the mediator - see the coupling architecture here.</li> <li>The coupled fields and remapping methods used are recorded in the mediator log output file and can be found with <code>grep '^ mapping' archive/output000/log/med.log</code>; see here for how to decode this.</li> <li>See the Configurations page for details on how the coupling is determined.</li> </ul>"},{"location":"Forcing-data-models/#input-data","title":"Input data","text":"<p><code>datm.streams.xml</code> and <code>drof.streams.xml</code> set individual input file paths for DATM and DROF respectively, relative to this entry in the <code>input</code> section of <code>config.yaml</code> (see the Configurations page).</p>"},{"location":"Forcing-data-models/#ice-surface-wind-stress","title":"Ice surface wind stress","text":"<p>This is calculated in CICE6 (IcePack). The wind velocity, specific humidity, air density and potential temperature at the level height <code>zlvl</code> (with optionally a different height <code>zlvs</code> for scalars) are used to compute transfer coefficients used in formulas for the surface wind stress and turbulent heat fluxes.</p> <p>The CICE6 forcing settings are in namelist group <code>forcing_nml</code> in <code>cice_in</code>. Many are unspecified and therefore take the default values. We use the default <code>atmbndy = 'similarity'</code>, which uses a stability-based boundary layer parameterisation based on Monin-Obukhov theory following Kauffman and Large (2002). Because our ice-ocean coupling frequency resolves inertial oscillations we use the non-default option <code>highfreq = .true.</code> (Roberts et al., 2015), which uses the relative ice-atmosphere velocity to calculate the wind stress on the ice. The exchange coefficients for momentum and scalars are determined iteratively, with a convergence tolerance <code>atmiter_conv</code> on <code>ustar</code> and maximum <code>natmiter</code> iterations. These take default values <code>atmiter_conv = 0.0</code> and <code>natmiter = 5</code>. We don't use spatiotemporally variable form drag (<code>formdrag = .false</code>, the default).</p>"},{"location":"Forcing-data-models/#ocean-surface-stress","title":"Ocean surface stress","text":"<p>Ocean surface stress is a combination of wind stress and ice-ocean stress. <code>Foxx_taux</code> and <code>Foxx_tauy</code> are the components of this combined surface stress received by the MOM6 cap, and are calculated in the mediator. <code>Foxx_taux</code> is a weighted sum of <code>Fioi_taux</code> (the ice-ocean stress) and <code>Faox_taux</code> (the atmosphere-ocean stress), weighted by the fraction of ice and open ocean in each cell. Similarly, <code>Foxx_tauy</code> is a weighted sum of <code>Fioi_tauy</code> and <code>Faox_tauy</code>. The prefix <code>Foxx</code> denotes an ocean (<code>o</code>) - mediator (<code>x</code>) flux (<code>F</code>) calculated by the mediator (<code>x</code>). Similarly <code>Fioi</code> denotes an ice (<code>i</code>) - ocean flux calculated by the ice component, and <code>Faox</code> indicates an atmosphere (<code>a</code>) - ocean flux calculated by the mediator (see here for details on this notation). Thus <code>Fioi_taux</code> is calculated in CICE6, whereas <code>Faox_taux</code> is calculated in the mediator (similarly for the y components).</p>"},{"location":"Forcing-data-models/#ice-ocean-stress","title":"Ice-ocean stress","text":"<p>The ice-ocean stress components <code>Fioi_taux</code> and <code>Fioi_tauy</code> are calculated in CICE6. <code>Fioi_taux</code> and <code>Fioi_tauy</code> are mapped from <code>tauxo</code> and <code>tauyo</code> in the CICE6 cap, which are in turn calculated in the CICE6 cap from <code>strocnxT_iavg</code> and <code>strocnyT_iavg</code>, which are per-ice-area quantities at T points calculated from per-cell-area stresses at U points <code>strocnxU</code> and <code>strocnyU</code>. <code>strocnxU</code> and <code>strocnyU</code> are calculated by subtroutine <code>dyn_finish</code> using this code; see equation (4) here and equation (2) here for an explanation. We use a turning angle $\\theta=0$ (<code>cosw = 1.0</code>, <code>sinw = 0.0</code>, the defaults), which is appropriate for an ocean component with vertical resolution sufficient to resolve the surface Ekman layer. We don't use spatiotemporally variable form drag (<code>formdrag = .false</code>, the default).</p> <p>TODO: what namelist controls the ice-ocean stress calculation? </p>"},{"location":"Forcing-data-models/#atmosphere-ocean-stress","title":"Atmosphere-ocean stress","text":"<p>The atmosphere-ocean stress components <code>Faox_taux</code> and <code>Faox_tauy</code> are calculated in the mediator. We calculate <code>Faox_taux</code> and <code>Faox_tauy</code> using <code>ocn_surface_flux_scheme = 0</code> in <code>nuopc.runconfig</code>, which is the default CESM1.2 scheme. This iterates towards convergence of <code>ustar</code> to a relative error of less than <code>flux_convergence = 0.01</code>, if this can be achieved in <code>flux_max_iteration = 5</code> iterations or fewer. The atmosphere-ocean stress is calculated using the relative wind, i.e. the difference between the surface wind and surface current velocity.</p>"},{"location":"Git-practices/","title":"Git practices","text":"<p>ACCESS-OM3 configurations that utilize the same model components are maintained as separate branches in one repo. For example, all ACCESS-OM3 MOM6-CICE6 configurations are branches in the <code>access-om3-configs</code> repo. This simplifies the syncing of changes across related configurations. In order to maintain clean and intuitive branch structure, the following practices should be followed:</p>"},{"location":"Git-practices/#configuration-branch-naming","title":"Configuration branch naming","text":"<p>Each configuration branch name should include as minimum the following: <code>dev/release-{nominal_resolution}deg_{forcing_data}_{forcing_method}</code> - e.g. <code>dev-01deg_jra55_ryf</code>. Additional required information can be appended if relevant, e.g. whether the configuration includes biogeochemistry.</p>"},{"location":"Git-practices/#feature-branch-naming","title":"Feature branch naming","text":"<p>All modifications to configuration branches should be carried out via a pull request from a feature branch. The name of the feature branch should be as follows: <code>{issue_number}-{configuration_branch}</code>, where <code>{issue_number}</code> is the number of a corresponding issue in the GitHub repo that provides context and information about the work being done in the feature branch - e.g. <code>99-dev-01deg_jra55_ryf</code>. Feature branches should be deleted once they are merged.</p>"},{"location":"Git-practices/#branch-synchronisation-for-releases","title":"Branch synchronisation for releases","text":"<p>Prior to a release, configuration branches should be synchronised by cherry-picking across all configurations and across repos, and a new release number created. The <code>!cherry-pick</code> GitHub action makes this easier:</p> <pre><code>!cherry-pick &lt;hash_1&gt; &lt;hash_2&gt; ... &lt;hash_n&gt; into &lt;branch_1&gt; &lt;branch_2&gt; ... &lt;branch_n&gt;\n</code></pre> <p>See https://github.com/ACCESS-NRI/access-om3-configs/pull/90.</p>"},{"location":"Git-practices/#production-runs","title":"Production runs","text":"<p>Production runs should be forked as separate repos, and the git runlog enabled.</p>"},{"location":"MOM6-generic-tracers/","title":"MOM6 generic tracers","text":"<p>NOAA-GFDL maintain a number of modules for modelling tracers, implemented via the GFDL \u201cgeneric_tracer\u201d API. These modules are \u201cgeneric\u201d in the sense that they can be used by both MOM and GOLD. They include a number of BGC models (BLING, COBALT, ERGOM, TOPAZ, miniBLING) and other useful tracers (e.g. CFC, SF6). The modules can be found here.</p> <p>Many of the GFDL generic_tracer modules require coupling with other components of the earth system. For example, BLING carries a number of tracers with associated air-sea gas fluxes, runoff fluxes or wet/dry deposition fluxes. Importantly, the additional fluxes required and associated coupled fields\u2014depends on which/how generic_tracers have been configured for use at runtime.</p> <p>In the generic_tracer modules, coupling of these additional tracer fluxes is handled via FMS coupler_types which are designed for use with the FMScoupler. Modifications to ACCESS-OM3 (which uses CMEPS/NUOPC for coupling, not FMScoupler) are required to allow the use of coupled generic_tracer modules. These modifications are described here.</p>"},{"location":"MOM6-generic-tracers/#background","title":"Background","text":""},{"location":"MOM6-generic-tracers/#fms-coupler-types","title":"FMS coupler types","text":"<p>In FMScoupler, the handling of tracer fluxes in a fully-coupled system revolves around three related FMS <code>coupler_1d_bc_type</code> data structures in <code>FMScoupler:flux_exchange_mod</code>:</p> <ul> <li><code>ex_gas_fields_atm</code>: for atmospheric surface fields associated with tracer fluxes and related parameters</li> <li><code>ex_gas_fields_ice</code>: for ice top and ocean surface fields associated with tracer fluxes and related parameters</li> <li><code>ex_gas_fluxes</code>: for tracer fluxes and related fields</li> </ul> <p>Together, these structures define the additional tracer fluxes required, the fields needed for their calculation, and the calculation method/parameters to use (defined by the flux type and implementation). A number of flux types and implementations can be used and are described in the <code>/coupler_mod/types/</code> field manager list (see here for where this list is defined). There are multiple implementations (i.e. calculation methods) for air-sea gas, air-sea deposition and land-sea runoff flux types. Each flux in the <code>ex_gas_*</code> structures has a type and implementation and is associated with an entry in the <code>/coupler_mod/fluxes/</code> field manager list.</p> <p>As an example, suppose we require an additional tracer flux <code>\"co2_flux\"</code> of type <code>\"air_sea_gas_flux_generic\"</code> and implementation <code>\"ocmip2\"</code> (<code>\u201docmip2\u201d</code> describes a particular method for calculating air-sea gas fluxes). After initialising the <code>ex_gas_*</code> structures with this flux, the relevant entry in the <code>/coupler_mod/types/</code> field manager list is:</p> <pre><code>air_sea_gas_flux_generic/\n      implementation/\n            ocmip2/\n                  num_parameters = 2\n            duce/\n                  num_parameters = 1\n            johnson/\n                  num_parameters = 2\n      num_flags = 0\n      use_atm_pressure = T\n      use_10m_wind_speed = T\n      pass_through_ice = F\n      atm/\n            name[1] = 'pcair'\n            name[2] = 'u10'\n            name[3] = 'psurf'\n            long_name[1] = 'Atmospheric concentration'\n            long_name[2] = 'Wind speed at 10 m'\n            long_name[3] = 'Surface atmospheric pressure'\n            units[1] = 'mol/mol'\n            units[2] = 'm/s'\n            units[3] = 'Pa'\n      ice/\n            name[1] = 'alpha'\n            name[2] = 'csurf'\n            name[3] = 'sc_no'\n            long_name[1] = 'Solubility w.r.t. atmosphere'\n            long_name[2] = 'Ocean concentration'\n            long_name[3] = 'Schmidt number'\n            units[1] = 'mol/m^3/atm'\n            units[2] = 'mol/m^3'\n            units[3] = 'dimensionless'\n      flux/\n            name[1] = 'flux'\n            name[2] = 'deltap'\n            name[3] = 'kw'\n            name[4] = 'flux0'\n            long_name[1] = 'Surface flux'\n            long_name[2] = 'Ocean-air delta pressure'\n            long_name[3] = 'Piston velocity'\n            long_name[4] = 'Surface flux no atm'\n            units[1] = 'mol/m^2/s'\n            units[2] = 'uatm'\n            units[3] = 'm/s'\n            units[4] = 'mol/m^2/s'\n</code></pre> <p>the <code>\"co2_flux\"</code> entry in the <code>/coupler_mod/fluxes/</code> field manager list is something like:</p> <pre><code>co2_flux/\n      flux_type = 'air_sea_gas_flux_generic'\n      implementation = 'ocmip2'\n      atm_tr_index = 0\n      mol_wt = 44.0099500000000\n      ice_restart_file = 'ice_bling.res.nc'\n      ocean_restart_file = 'ocean_bling_airsea_flux.res.nc'\n      param[1] = 9.360000000000000E-007\n      param[2] = 9.756100000000000E-006\n      flag = NULL\n      flux-units = 'mol/m^2/s'\n      flux-long_name = 'Surface flux'\n      deltap-units = 'uatm'\n      deltap-long_name = 'Ocean-air delta pressure'\n      kw-units = 'm/s'\n      kw-long_name = 'Piston velocity'\n      flux0-units = 'mol/m^2/s'\n      flux0-long_name = 'Surface flux no atm'\n      pcair-units = 'mol/mol'\n      pcair-long_name = 'Atmospheric concentration'\n      u10-units = 'm/s'\n      u10-long_name = 'Wind speed at 10 m'\n      psurf-units = 'Pa'\n      psurf-long_name = 'Surface atmospheric pressure'\n      alpha-units = 'mol/m^3/atm'\n      alpha-long_name = 'Solubility w.r.t. atmosphere'\n      csurf-units = 'mol/m^3'\n      csurf-long_name = 'Ocean concentration'\n      sc_no-units = 'dimensionless'\n      sc_no-long_name = 'Schmidt number'\n</code></pre> <p>and (assuming <code>ind_co2</code> is the index for the <code>\"co2_flux\"</code> flux): - <code>ex_gas_fields_atm%bc(ind_co2)</code> is initialised to carry the fields <code>pcair</code>, <code>u10</code> and <code>psurf</code> - <code>ex_gas_fields_ice%bc(ind_co2)</code> is initialised to carry the fields <code>alpha</code>, <code>csurf</code> and <code>sc_no</code> - <code>ex_gas_fluxes%bc(ind_co2)</code> is initialised to carry the fields <code>flux</code>, <code>deltap</code>, <code>kw</code> and <code>flux0</code></p> <p>During a coupling loop with FMScoupler the fields for each flux in <code>ex_gas_fields_atm</code> and <code>ex_gas_fields_ice</code> are set and the fluxes in <code>ex_gas_fluxes</code> are calculated from these fields. Importantly, the arrays in the <code>ex_gas_*</code> structures are 1-dimensional (<code>coupler_1d_bc_type</code>). They will store the fields on the exchange grid used in FMScoupler.</p>"},{"location":"MOM6-generic-tracers/#additional-tracer-flux-handling","title":"Additional tracer flux handling","text":"<p>A (greatly) simplified summary of the handling of additional tracer fluxes in FMScoupler is as follows:</p> <ul> <li>Initialise <code>ex_gas_fields_atm</code>, <code>ex_gas_fields_ice</code> and <code>ex_gas_fluxes</code> for the additional tracer fluxes. This step calls initialisation routines within the ocean and atmosphere models to determine what additional tracer fluxes are required. No field arrays set at this point. (via <code>gas_exchange_init</code>).</li> <li>Spawn a 2D version, <code>Ocean%fields</code> (<code>coupler_2d_bc_type</code>), of <code>ex_gas_fields_ice</code>. (via <code>ocean_model_init</code>)</li> <li>Calculate/set field arrays for <code>alpha</code>, <code>csurf</code> and <code>sc_no</code> for air-sea gasfluxes in <code>Ocean%fields</code>. (via <code>ocean_model_init</code>)</li> <li>Spawn a 2D version, <code>Atm%fields</code>, of <code>ex_gas_fields_atm</code>. (via <code>flux_exchange_init</code>)</li> <li>Spawn a 2D version, <code>Ice_ocean_boundary%fluxes</code>, of <code>ex_gas_fluxes</code>. (via <code>flux_exchange_init</code>)</li> <li>&gt;&gt;&gt; Begin coupling loop</li> <li>Set arrays for <code>pcair</code> (air-sea gas fluxes) and <code>deposition</code> (air-sea deposition fluxes) in <code>Atm%fields</code>. (via <code>atmos_tracer_driver_gather_data</code>)</li> <li>Set arrays for <code>u10</code> and <code>psurf</code> for air-sea gas fluxes in <code>Atm%fields</code>. (via <code>sfc_boundary_layer</code>)</li> <li>Map <code>Ocean%fields</code> and <code>Atm%fields</code> onto exchange grid to set 1D fields in <code>ex_gas_fields_ice</code> and <code>ex_gas_fields_atm</code>, respectively. (via <code>sfc_boundary_layer</code>)</li> <li>Calculate fluxes <code>ex_gas_fluxes</code> from <code>ex_gas_fields_ice</code> and <code>ex_gas_fields_atm</code> according to flux types and implementations. (via <code>sfc_boundary_layer</code>)</li> <li>Update atmosphere (this is actually done in multiple steps within a fast coupling loop, but here we\u2019ve simplified)</li> <li>Map 1D <code>ex_gas_fluxes</code> fields onto 2D <code>Ice_ocean_boundary%fluxes</code> (via <code>flux_down_from_atmos</code> and <code>flux_atmos_to_ocean</code>)</li> <li>Update land (this is actually done in multiple steps across two coupling loops, but here we\u2019ve simplified)</li> <li>Update ice (this is actually done in multiple steps across two coupling loops, but here we\u2019ve simplified)</li> <li>Update ocean, applying <code>Ice_ocean_boundary%fluxes</code>. Calculate/set field arrays for <code>alpha</code>, <code>csurf</code> and <code>sc_no</code> for air-sea gas fluxes in <code>Ocean%fields</code>. (via <code>update_ocean_model</code>)</li> <li>&lt;&lt;&lt; End coupling loop</li> </ul>"},{"location":"MOM6-generic-tracers/#schematic-summary","title":"Schematic summary","text":"<p>The schematic below traces the handling of additional tracer fluxes in more detail and shows where simplifications were made in the above summary. Note that I generated this schematic by reading the source code and it hasn\u2019t (yet) been verified by any FMScoupler developer. To the best of my knowledge it is mostly complete/correct but I make no guarantees.</p> <p></p>"},{"location":"MOM6-generic-tracers/#nuopc-coupled-mom6-and-generic_tracers","title":"NUOPC-coupled MOM6 and generic_tracers","text":"<p>Code changes are required to allow the use of coupled generic_tracers with NUOPC-coupled MOM6. These changes are guided by the following design principles:</p> <ul> <li>Use exisiting code where possible, with as little change as possible</li> <li>Avoid making edits to source code in MOM6 or GFDL generic_tracer modules</li> </ul> <p>The code changes are limited to the MOM6 NUOPC cap and broadly do as follows:</p> <ol> <li>Initialisation phases<ol> <li>Initialise <code>coupler_1d_bc_type</code> data structures <code>ex_gas_fields_atm</code>, <code>ex_gas_fields_ocn</code> and <code>ex_gas_fluxes</code>. Note these structures are never actually populated with data (unlike in FMScoupler) - they are just used to spawn 2D structures (<code>coupler_2d_bc_type</code>).</li> <li>Initialise ocean model with (a pointer to) <code>ex_gas_fields_ocn</code> to populate relevant fields.</li> <li>Spawn 2D <code>Ice_ocean_boundary%fluxes</code> from (a pointer to) <code>ex_gas_fluxes</code>.</li> <li>Spawn 2D <code>atm_fields</code> from (a pointer to) <code>ex_gas_fields_atm</code>.</li> <li>Using (a pointer to) <code>ex_gas_fluxes</code>, register with NUOPC the additional atmospheric import fields required flux calculations. Field export has not yet been implemented.</li> </ol> </li> <li>Advance phase<ol> <li>Get/set atmospheric fields in <code>atm_fields</code> from the coupler.</li> <li>Calculate the fluxes in <code>Ice_ocean_boundary%fluxes</code> using a modified version of the routine used by FMScoupler that operates on FMS <code>coupler_2d_bc_type</code> inputs.</li> </ol> </li> </ol> <p>The additional fluxes will be applied from <code>Ice_ocean_boundary%fluxes</code> when the model is advanced.</p>"},{"location":"MOM6-generic-tracers/#code-structure","title":"Code structure","text":"<p>The most important changes made include modifications to:</p> <ul> <li><code>MOM6/config_src/drivers/nuopc_cap/mom_cap.F90</code></li> <li><code>MOM6/config_src/drivers/nuopc_cap/mom_cap_methods.F90</code></li> </ul> <p>and the addition of a new module to the NUOPC cap: <code>mom_cap_gtracer_flux.F90</code></p> <p>Code modifications/additions have been made via patch files found in the <code>MOM6/patches</code> directory. The new module can be found in the <code>MOM6/extra_sources</code> directory.</p>"},{"location":"MOM6-generic-tracers/#the-mom_cap_gtracer_flux-module","title":"The <code>mom_cap_gtracer_flux</code> module","text":"<p>This is where most of the new code is, with many of the changes to <code>mom_cap.F90</code> and <code>mom_cap_methods.F90</code> being calls to routines defined here. This module also includes the data structures <code>ex_gas_fields_atm</code>, <code>ex_gas_fields_ocn</code> and <code>ex_gas_fluxes</code>. Public routines are:</p> <ul> <li><code>gas_exchange_init</code>: initialise <code>ex_gas_fields_atm</code>, <code>ex_gas_fields_ocn</code> and <code>ex_gas_fluxes</code> and optionally returns pointers to them.</li> <li><code>gas_fields_restore</code>: restore an FMS <code>coupler_2d_bc_type</code> state from the ocean restart file defined internally.</li> <li><code>gas_fields_restart</code>: write restart for an FMS <code>coupler_2d_bc_type</code> to the ocean restart file defined internally.</li> <li><code>add_gas_fluxes_param</code>: for each flux in an FMS <code>coupler_2d_bc_type</code>, retrieve the <code>param</code> array from the <code>/coupler_mod/fluxes/</code> field manager list and set it in the <code>coupler_2d_bc_type</code>. This is only needed because spawning a <code>coupler_*d_bc_type</code> does not copy the <code>param</code> array into the spawned type.</li> <li><code>get_coupled_field_name</code>: provides the CMEPS field standard name of any fields that need to be coupled for a given generic_tracer flux name. Currently only generic_tracer fluxes <code>\"co2_flux\"</code> and <code>\"o2_flux\"</code> have been implemented.</li> <li><code>atmos_ocean_fluxes_calc</code>: calculates the tracer fluxes according to their flux type and implementation. This routine was copied from FMScoupler and modified. Key modifications include:<ul> <li>Operate on <code>coupler_2d_bc_type</code> inputs, rather than <code>coupler_1d_bc_type</code>.</li> <li>Include calculation for <code>\"air_sea_deposition\"</code> flux types (which in FMScoupler is done in a separate step)</li> <li>Account for sea-ice fraction (in FMScoupler this is done as part of the exchange grid mapping)</li> <li>Make <code>tsurf</code> input optional, as it is only used by a few implementations</li> </ul> </li> </ul>"},{"location":"MOM6-generic-tracers/#schematic-summary_1","title":"Schematic summary","text":"<p>The schematic below traces the handling of coupled generic_tracer fluxes in the MOM6 NUOPC cap.</p> <p></p>"},{"location":"MOM6-generic-tracers/#diagnostics","title":"Diagnostics","text":"<p>Diagnostics can be output for the FMS <code>coupler_2d_bc_type</code> fields involved in the handling of the tracer fluxes (flux fields: <code>Ice_ocean_boundary%fluxes</code>, ocean fields: <code>ocean_public%fields</code>, atmos fields: <code>atm_fields</code>). The \u201cmodel_name\u201d for each type is: flux fields: <code>\u201cocean_flux\u201d</code>, ocean fields: <code>\u201cocean_sfc\u201d</code>, atmos fields: <code>\u201catmos_sfc\u201d</code>. The naming convention for diagnostics of FMS <code>coupler_bc_type</code>s is: <code>&lt;flux_name&gt;_&lt;field_name&gt;_&lt;suffix&gt;</code>, where <code>&lt;suffix&gt;</code> is <code>\u201d_ice_ocn\u201d</code>, <code>\u201d_ocn\u201d</code> and <code>\u201d_atm\u201d</code> for the flux, ocean and atmos fields, respectively. For example, the surface flux field for the <code>\u201dco2_flux\u201d</code> example above is called <code>\u201dco2_flux_flux_ice_ocn\u201d</code>.</p> <p>The flux and atmos diagnostics are sent immediately after the tracer flux calculation is done, prior to advancing the model. The ocean diagnostics are sent after advancing the model. This means that the flux/atmos diagnostics are not available at Tfinal+dt (whereas the ocean diagnostics are) and the ocean diagnostics are not available at Tstart (whereas the flux/atmos diagnostics are).</p>"},{"location":"MOM6-generic-tracers/#data-override","title":"Data override","text":"<p>FMS data override functionality has been added to allow the tracer fluxes and the contributing atmospheric fields to be overridden via a <code>data_table</code> using the component name <code>\"OCN\"</code>. The naming convention for overriding fields is as described above. E.g. one could override the atmospheric concentration field for the <code>\u201dco2_flux\u201d</code> example above using the fieldname <code>\u201dco2_flux_pcair_atm\u201d</code></p>"},{"location":"MOM6/","title":"MOM6","text":""},{"location":"MOM6/#mom6-info-docs-etc","title":"MOM6 info, docs, etc","text":"<ul> <li>MOM6 homepage</li> <li>MOM6 wiki</li> <li>MOM6 documentation</li> <li>MOM6 tutorial videos (also see here) and an older overview of MOM6 numerics</li> <li>MOM6 discussion forum</li> </ul>"},{"location":"MOM6/#related-projects","title":"Related projects","text":"<p>We draw on experience from our other MOM6 projects, e.g. - our global MOM6 configuration https://github.com/COSIMA/mom6-om4-025 - MOM6 regional configuration generator https://github.com/COSIMA/mom6-regional - our MOM6 PanAntarctic regional configuration https://github.com/COSIMA/mom6-panan - our MOM6 EAC regional configuration https://github.com/COSIMA/mom6-eac - Claire Yung's ice shelf tools https://github.com/claireyung/mom6-panAn-iceshelf-tools</p>"},{"location":"NUOPC-driver/","title":"NUOPC driver","text":"<p>We have adopted the NUOPC driver from CESM.</p>"},{"location":"NUOPC-driver/#component-initialisation","title":"Component initialisation","text":"<p>Model component initialisation strategy is specified through a combination of flags set in the <code>nuopc.runconfig</code> configuration file and the input parameter files for each component.</p> <p>The <code>start_type</code> parameter in the <code>ALLCOMP_attributes</code> section of <code>nuopc.runconfig</code> can be set to one of three values (note that the <code>access-om3</code> Payu driver automatically sets this parameter depending on whether the run is an initial or restart run):</p> <ul> <li><code>\"startup\"</code> specifying an initial run,</li> <li><code>\"continue\"</code> specifying a run starting from restart files,</li> <li><code>\"branch\"</code> specifying a run starting from restart files in which properties of the output history files may be changed - not used here.</li> </ul> <p>These have the following effects on each ACCESS-OM3 component\u2019s parameters settings:</p>"},{"location":"NUOPC-driver/#mom6","title":"MOM6","text":"<p>See MOM6 NUOPC cap for details.</p> <code>start_type</code> Interaction with model parameters (from <code>input.nml</code>) <code>\"startup\"</code> Sets parameter <code>restartfiles = \"n\"</code>. <code>\"continue\"</code> / <code>\"branch\"</code> Hardcoded to use restart file specified in a local file <code>rpointer.ocn</code>. <p>Note, users should let NUOPC set the <code>restartfiles</code> parameter. It should not be specified in <code>input.nml</code>.</p>"},{"location":"NUOPC-driver/#cice6","title":"CICE6","text":"<p>See CICE6 NUOPC cap for details.</p> <code>start_type</code> Interaction with model parameters (from <code>ice_in</code>) <code>\"startup\"</code> Sets parameter <code>runtype = \"initial\"</code>. The type of CICE startup can be further configured using the <code>ice_ic</code> parameter in <code>ice_in</code> - see here. <code>\"continue\"</code> / <code>\"branch\"</code> Sets parameters <code>restart = .true.</code> , <code>runtype = \"continue\"</code> and <code>use_restart_time = .true.</code> so uses restart specified in file specified in parameter <code>pointer_file</code>. <p>Note, users should let NUOPC set the <code>restart</code>, <code>runtype</code> and <code>use_restart_time</code> parameters. They should not be specified in <code>ice_in</code>.</p>"},{"location":"NUOPC-driver/#cdeps-components-datm-drof","title":"CDEPS components (DATM, DROF)","text":"<p>See e.g. the atm NUOPC cap and patch, and here for details.</p> <code>start_type</code> Interaction with model parameters (from <code>d{model_name}_in</code>) <code>\"startup\"</code> Does not attempt to read any restarts regardless of parameter values. <code>\"continue\"</code> / <code>\"branch\"</code> If parameter <code>skip_restart_read = .false.</code>, then reads restart specified in file <code>rpointer.{model_name}</code> or reads restart specified in parameter <code>restfilm</code> if it isn't set to <code>\"null\"</code> - see here. <p>Note, restarts are used for the CDEPS components in ACCESS-OM3 only for performance reasons. They\u2019re not needed to restart exactly, but they reduce startup cost associated with reading the input dataset time axis information - see here for more detail.</p>"},{"location":"NUOPC-driver/#time-steps","title":"Time-steps","text":"<p>Also see timestepping section here.</p>"},{"location":"NUOPC-driver/#coupling-and-driver-time-step","title":"Coupling and driver time-step","text":"<p>There's an overview of the NUOPC timekeeping design here.</p> <p>The <code>nuopc.runseq</code> file specifies the run sequence of the configuration. The run sequence for current ACCESS-OM3 configurations comprises a single loop, with the coupling time-step specified at the start of the loop (this is the \u201ctimeStep\u201d of the loop in NUOPC-speak).</p> <p>Note, that there are parameters <code>{model_name}_cpl_dt</code> set in the <code>CLOCK_attributes</code> section of <code>nuopc.runconfig</code>. The only place these are used in CMEPS is to set the driver time-step as the minimum of these values. However from the NUOPC documentation and CMEPS codebase:</p> <p>Each time loop has its own associated clock object. NUOPC manages these clock objects, i.e. their creation and destruction, as well as startTime, endTime, timeStep adjustments during the execution. The outer most time loop of the run sequence is a special case. It uses the driver clock itself. If a single outer most loop is defined in the run sequence provided by freeFormat, this loop becomes the driver loop level  directly. Therefore, setting the timeStep or runDuration for the outer most time loop results modifying the driver clock itself. However, for cases with concatenated loops on the upper level of  the run sequence in freeFormat, a single outer loop is added automatically during ingestion, and the driver clock is used for this loop instead.</p> <p>So I think in our case, <code>{model_name}_cpl_dt</code> are unused and the driver time-step equals the coupling time-step set in <code>nuopc.runseq</code>. Certainly, changing these values seems to have no effect. However, I would feel more comfortable if I understood why <code>{model_name}_cpl_dt</code> are ever needed...</p>"},{"location":"NUOPC-driver/#cice6-time-steps","title":"CICE6 time-steps","text":"<p>The CICE thermodynamics time-step (<code>dt</code>) is set in the CICE NUOPC cap to match the driver time-step, which equals the coupling time-step. Note that this is done before the CICE namelist file (<code>ice_in</code>) is read. Thus issues will occur if <code>dt</code> is set in <code>ice_in</code> but does not match the coupling time-step. It's therefore probably safest not to set <code>dt</code> in <code>ice_in</code>, although other time-step related parameters can be set here. Setting <code>ndtd</code> within <code>ice_in</code> allows for sub-cycling of the sea-ice dynamics to ensure numerical stability and may need to be increased during initial model spin up (the thermodynamics should be numerically stable for any time-step).</p>"},{"location":"NUOPC-driver/#mom6-time-steps","title":"MOM6 time-steps","text":"<p>MOM6 has 4 timesteps - see here and here and here. From shortest to longest they are: barotropic, baroclinic (Lagrangian), tracer, and vertical remapping. Of these, it is common to set at least these 3 timesteps in the <code>MOM_input</code> file:</p> <ul> <li> <p>Barotropic time-step (<code>DTBT</code>) for integration of sea surface and depth-averaged horizontal velocity. If set negative (e.g. <code>DTBT = -0.95</code>), the magnitude of <code>DTBT</code> is interpreted a fraction of the stability limit, so can be set independently of the model configuration (e.g. resolution). <code>DTBT_RESET_PERIOD</code> controls how often the stability limit is recalculated.</p> </li> <li> <p>Baroclinic time-step (<code>DT</code>) for Lagrangian stacked shallow-water equations; often called \"the\" model timestep; needs to be short enough to resolve internal gravity waves, inertial oscillations and advection on the horizontal grid (i.e. this is resolution-dependent).</p> </li> <li> <p>Tracer/thermodynamics time-step (<code>DT_THERM</code>), which can be set to resolve the relevant physics (e.g. an hour or so to capture the diurnal cycle), independent of the horizontal grid resolution. It is possible to set <code>DT_THERM</code> longer than the coupling time-step, but not with <code>DIABATIC_FIRST = True</code>, which is the case for the current ACCESS-OM3 configurations. So <code>DT_THERM</code> should be set equal to, or less than, the coupling time-step.</p> </li> </ul>"},{"location":"Quick-start/","title":"Quick start","text":""},{"location":"Quick-start/#building-access-om3-executable-optional","title":"Building <code>access-om3</code> executable (optional)","text":"<p>You probably won't need to build the model yourself. ACCESS-OM3 configurations are already set up to use precompiled executables from the latest stable release. Precompiled executables from other releases are also available.</p> <p>However, if you want to make code changes you'll need to build access-om3 yourself.</p>"},{"location":"Quick-start/#downloading-a-configuration","title":"Downloading a configuration","text":"<p>Configurations that use the same combination of model components (MOM6, CICE6 and/or WW3) are stored as separate branches in a single repository, as listed here. The main branch within each of these repositories is just documentation. To get a working configuration you need to check out one of the branches with the resolution and forcing details you need, as explained in the README of the configuration repo. It's also best to create your own fork and clone that, so you can back up your work there.</p> <p>For example, to run a <code>MOM6-CICE6</code> configuration under RYF JRA55-do forcing (i.e. the <code>1deg_jra55do_ryf</code> branch): 1. fork the repo https://github.com/ACCESS-NRI/access-om3-configs on GitHub (if you haven't already), unchecking the \"Copy the main branch only\" box so you get all the configuration branches 2. choose a unique name for your experiment, e.g. <code>my_1deg_jra55do_ryf_experiment_name</code> 3. <code>cd</code> to somewhere in your <code>/home</code> directory on Gadi (since this is the only filesystem that's backed up) 4. clone the config from your fork: <code>git clone git@github.com:&lt;username&gt;/access-om3-configs.git my_1deg_jra55do_ryf_experiment_name</code> (where <code>&lt;username&gt;</code> is your GitHub user name) 5. <code>cd my_1deg_jra55do_ryf_experiment_name</code> 6. check out the branch of interest: <code>git checkout dev-1deg_jra55do_ryf</code> 7. check out a new branch to store your run: <code>git checkout -b my_1deg_jra55do_ryf_experiment_name</code> so you can use git to easily see how your run configuration differs from the original 8. edit <code>config.yaml</code> to set the following flags. These will record your configuration settings in the git history as the run proceeds, and also generate a unique identifier for your experiment.</p> <pre><code>runlog: true\nmetadata:\n  enable: true\n</code></pre> <ol> <li>If you've compiled your own executable you'll also need to edit the <code>exe</code> entry in <code>config.yaml</code> to point to it.</li> </ol>"},{"location":"Quick-start/#customising-your-experiment","title":"Customising your experiment","text":"<p>You may want change the run length. This is determined by <code>stop_n</code> and <code>stop_option</code> in <code>CLOCK_attributes</code> in <code>nuopc.runconfig</code>; available units for <code>stop_option</code> are listed here. See the Configurations section to find out how to set other parameters.</p> <p>Before running, commit your changes with an informative message, e.g. <code>git commit -am \"initial setup for experiment to test... bla bla\"</code></p>"},{"location":"Quick-start/#running","title":"Running","text":"<p>Running ACCESS-OM3 requires an updated <code>payu</code>, available from the <code>vk83</code> project - apply here if you're not yet a member. You then need to do the following before you can run (only needs to be done once per log in, or you can put this in your <code>~/.bash_profile</code> to do it automatically each login):</p> <pre><code>module use /g/data/vk83/modules\nmodule load payu\n</code></pre> <p>Now you're ready to run:</p> <pre><code>payu run\n</code></pre> <p>This uses the payu workflow management tool to prepare the run and submit it as a job to the PBS job queue. See the Gadi User Guide to learn more about PBS job management.</p> <p>Check the status of the job (state 'Q'=waiting in queue, 'R'=running, 'E'=exiting, 'H'=held) with</p> <pre><code>#this is needed for uqstat to be available \nmodule use /g/data/hh5/public/modules\nmodule load nci-scripts\n\nuqstat -c\n</code></pre> <p>While it's running, you can check the date it's up to with</p> <pre><code>grep date work/log/med.log\n</code></pre> <p>To kill the run early, do <code>qdel N</code>, where N is the job number (first column given by <code>uqstat</code>). If you kill the job (or it crashes), a <code>work</code> directory will be left behind after the job has disappeared from <code>uqstat</code> and you'll need to do <code>payu sweep</code> before you can run again.</p> <p>When your run has finished successfully, payu puts its output in <code>archive/output000</code> and removes the <code>work</code> directory. payu also records a log of your experiment in the git history, including the identity of the inputs and executables used (see the files in <code>manifests</code>).</p> <p>To do another run, just type <code>payu run</code> again. Or to do (say) 10 runs, type <code>payu run -n 10</code> and they'll automatically be submitted one after the other.</p> <p>The outputs from each run will be in numbered subdirectories in <code>archive</code>.</p> <p>Each run creates a <code>restart</code> directory in <code>archive</code> which is used as the initial condition for the next run. These restarts can accumulate and consume disk space, but only the most recent one is needed (unless you plan to restart a new experiment from an intermediate state). See the payu documentation for more information.</p> <p>If the run fails, the <code>work</code> directory will be retained. You can find diagnostic messages in <code>access-om3.*</code>, <code>MOM6-CICE6.[oe]*</code>, <code>work/log/*</code>, <code>work/logfile*</code> and other files in <code>work</code>. You will need to do <code>payu sweep</code> to delete the <code>work</code> directory before you will be able to do another <code>payu run</code>. This will also save copies of the PBS logs into <code>archive/pbs_logs</code>.</p> <p>WARNING restarts and outputs are stored on <code>/scratch</code> and will therefore be deleted if unread for 100 days, so if you value them you should move them somewhere safer, e.g. <code>/g/data</code>. Note that <code>/home</code> is the only filesystem that is backed up, so your configuration should live there, but you probably won't have room for outputs and restarts. If you put a <code>sync</code> section in <code>config.yaml</code>, payu will automatically copy your files to a safe location you specify.</p>"},{"location":"Releases/","title":"Releases","text":""},{"location":"Releases/#releases","title":"Releases","text":"<p>There are several ACCESS-OM3 releases available.</p> <p>Precompiled executables of these are available via spack packages in</p> <pre><code>/g/data/ik11/spack/*/modules/access-om3\n</code></pre> <p>(Access requires membership of the <code>ik11</code> project - apply here if needed.)</p> <p>Those matching ACCESS-OM3 releases are stable, and generally the newest is the recommended version for general use. Those containing \"x\" are unstable development versions which can change without notice.</p> <p>Executables themselves can be found via</p> <pre><code>find /g/data/ik11/spack/*/opt -name \"access-om3-*CICE6*\"\n</code></pre> <p>The file path includes the full ACCESS-OM3 commit hash indicating the sources used.</p> <p>To switch to one of these you need to change the <code>exe:</code> and <code>modules: use:</code> entries in <code>config.yaml</code> in a consistent way - see here for full details. You also need to change the <code>input:</code> entries to the matching version number.</p>"},{"location":"Topography-generation/","title":"ACCESS-OM3 Topography Workflow","text":""},{"location":"Topography-generation/#introduction","title":"Introduction","text":"<p>The supported ACCESS-OM3 configurations now use a topography based on the GEBCO2024 global topography dataset. This dataset maintains a high resolution of 15 arc-seconds (i.e., 1/240 deg = ~460m at the equator and finer zonally near the poles).</p>"},{"location":"Topography-generation/#bathymetry-tools","title":"Bathymetry Tools","text":"<p>The workflow described below uses <code>bathymetry-tools</code> to perform specific tasks, such as removing seas or generating the land/sea mask. Instructions to install <code>bathymetry-tools</code> can be found here.</p>"},{"location":"Topography-generation/#general-workflow","title":"General Workflow","text":"<p>The general workflow for generating the OM3 topography and corresponding land/sea masks is as follows:</p> <ol> <li>Interpolate GEBCO2024 data onto the model grid.</li> <li>Adjust C-grid connectivity using the <code>deseas</code> algorithm to ensure marginal seas with 1-cell-wide outlets (e.g., Gibraltar) remain connected to the ocean.</li> <li>Remove T cells that are smaller than the given threshold.</li> <li>Fill cells with a sea area fraction smaller than 0.5.</li> <li>Apply manual topography edits using <code>editTopo.py</code>.</li> <li>Remove isolated seas.</li> <li>Apply minimum and maximum allowed ocean depths.</li> <li>Generate the land/sea mask from the topography.</li> <li>Generate additional necessary model input files, such as ESMF meshes and runoff remapping weights.</li> </ol> <p>This workflow assumes that a horizontal super-grid has already been created and that the model uses a C-grid. Some manual editing may still be necessary to refine the topography.</p> <p>For a complete workflow and instructions on generating OM3 topography, refer to the make_OM3_025deg_topo repository.</p>"},{"location":"Updating-components/","title":"Updating components","text":"<p>All the components that make up OM3 (models, coupler, etc) are currently included as git submodules and built using CMake. This means that, in a nutshell, updating a given component usually requires updating the git submodule and the CMake build system.</p>"},{"location":"Updating-components/#step-by-step-instructions","title":"Step by step instructions","text":""},{"location":"Updating-components/#submodule-update","title":"Submodule update","text":"<p>Although not required, we recommend starting the process from a clean git repository:</p> <pre><code>git clone --recursive https://github.com/COSIMA/access-om3.git\n</code></pre> <p>Next, go to the directory of the component to update. For example, to update MOM6:</p> <pre><code>cd access-om3/MOM6/MOM6\n</code></pre> <p>and checkout the branch/tag/commit you want to update to:</p> <pre><code>git checkout &lt;branch/tag/commit&gt;\n</code></pre> <p>Some of the components have git submodules themselves. If that's the case, they need also need to be updated:</p> <pre><code>git submodule update --recursive\n</code></pre>"},{"location":"Updating-components/#cmake-update","title":"CMake update","text":"<p>Quite often the changes to the component's sources will include addition and/or removal of files. When this happens, the CMake build system also need to be updated accordingly. The sources are listed in the <code>CMakeLists.txt</code> files that one can find in each component subdirectory. For example, in the case of WW3, that's the WW3/CMakeLists.txt<code>(not</code>WW3/WW3/CMakeLists.txt`!).</p> <p>At this point, it might also happen that some patches are not necessary anymore and they will throw an error when building the code. If this happens, one needs to update the corresponding patch. If no patch at all is needed after the update, the corresponding patch should be removed from the git repository:</p> <pre><code>git rm &lt;COMPONENT&gt;/patches/&lt;file&gt;.F90_patch\n</code></pre> <p>and the original source file needs to be moved from the list of sources to patch to the \"normal\" source files list in <code>CMakeLists.txt</code>. The changes should look like this:</p> <pre><code> target_sources(OM3_&lt;target&gt; PRIVATE\n   ...\n+  &lt;file&gt;\n   ...\n )\n ...\n-add_patched_source(OM3_&lt;target&gt; &lt;file&gt;)\n</code></pre>"},{"location":"Updating-components/#new-releases","title":"New Releases","text":"<p>When it is needed to update the model components to incorporate new upstream updates, this triggers a new minor release. These are the high-level steps to update the model component versions: 1. Choose new component versions: These need to be chosen based on currently known issues/bugs and desired features in the new release. The versions in https://github.com/ESCOMP/CESM/blob/cesm3.0-alphabranch/.gitmodules are a good starting point, as we know NCAR have already checked for compatibility between these versions. 2. Update ACCESS-NRI forks: Where a component is built from an ACCESS-NRI fork, this fork needs updating (at time of writing this is MOM6 &amp; CICE6). Before changing the default branch of the fork, ensure the current state is captured in a <code>&lt;&lt;version&gt;&gt;</code> branch, where version is typically <code>YYYY.MM</code> . The branching practice is described for MOM6 here and the CICE process is very similar. The default branch of the fork then needs updating to the desired code version and any ACCESS specific commits that are not included in the upstream version reapplied (e.g. through a git rebase or cherry-pick). This probably requires a force push to change the history on the default branch. 3. Update dependency versions: Based on any new releases available, update the dependencies. These are releases of code which are not access-om3 model components, they are code which the models depend on (e.g. openmpi, netcdf, fms etc). The versions can be changed in the access-om deployment repository by changing the spack.yaml. Unless there is an interface change, the old access-om3 model components should still build with the new dependencies (try building through spack). 4. Update model components: Its easiest to use a spack \"develop\" environment at this point. For each model component, update the submodule to the desired version. Fix any patches applies by CMAKE so that the model builds. If there are bugs found, raise in the appropriate upstream repository. 5. Test the build: Once you have a build with the new components, try running the build using typical configs (e.g. https://github.com/accESS-NRI/access-om3-configs and https://github.com/accESS-NRI/access-om3-wav-configs). The config will often need the field dictionary updated from upstream. Each model component and cap may have other changes as described in the release note / git history for that component. Work through any issues and updates until the model runs.  6. Release the build: Once you are happy with the build, tag each model component fork with the new release number (typically CalVer) and this repository with a new release minor release number (e.g. 0.x.0). 7. Deploy: Deploy the new version, using the new release numbers using the CD process in https://github.com/ACCESS-NRI/ACCESS-OM3 8. Update the configurations: Update all https://github.com/accESS-NRI/access-om3-configs and https://github.com/accESS-NRI/access-om3-wav-configs dev-branches with the build from the new access-om3 deployment &amp; related changed (e.g. <code>fd.yaml</code> and other config changes needed for it to run, including minimum payu version) 9. Tag the update configurations: Tag the updated configuration with the new access-om3 release version.</p>"}]}